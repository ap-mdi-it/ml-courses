{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8a86f893",
            "metadata": {},
            "source": [
                "# Airbnb prijsvoorspelling\n",
                "\n",
                "Gebaseerd op: [Airbnb : price prediction using XGBoost ðŸ”¥](https://www.kaggle.com/code/noufalmalki/airbnb-price-prediction-using-xgboost/notebook)\n",
                "\n",
                "## Probleem definitie\n",
                "Airbnb gebruikt machine learning om optimale prijsvoorstellen te doen aan hosts. Een goed gekalibreerd prijsmodel helpt hosts hun omzet te maximaliseren en tegelijkertijd concurrerend te blijven.\n",
                "\n",
                "### Taak, Ervaring\n",
                "De bedoeling is om numerieke waarden te voorspellen (prijs). Dit gaat over een _regressie_taak. We willen trainen aan de hand van effectieve prijzen. We hebben dus te maken met _gesuperviseerd_ leren.\n",
                "\n",
                "## _Data collection_\n",
                "We gebruiken een dataset van Airbnb die beschikbaar is op [Kaggle](https://www.kaggle.com/datasets/stevezhenghp/airbnb-price-prediction) met prijzen uit verschillende grote Amerikaanse steden. We richten ons op volgende variabelen:\n",
                "- **Numeriek**: bedrooms, bathrooms, review scores, etc.\n",
                "- **Categorisch**: property type, room type, city, amenities\n",
                "- **Text**: amenities\n",
                "- **Geografisch**: latitude, longitude, neighborhood\n",
                "- **Target variable**: `log_price`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "91801a59",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "\n",
                "import kagglehub\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "import xgboost as xgb\n",
                "from sklearn.linear_model import LinearRegression, Ridge\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "from sklearn.model_selection import cross_val_score, train_test_split\n",
                "from sklearn.preprocessing import OneHotEncoder\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33e28be6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "path = kagglehub.dataset_download(\"stevezhenghp/airbnb-price-prediction\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2fca064a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(os.path.join(path, \"train.csv\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5da20ef0",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a61db5c6",
            "metadata": {},
            "source": [
                "## _Data exploration_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e48bc368",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic information about our dataset\n",
                "print(\"Dataset Information:\")\n",
                "print(\"=\" * 50)\n",
                "df.info()\n",
                "\n",
                "print(\"\\nTarget Variable Statistics:\")\n",
                "print(\"=\" * 50)\n",
                "print(df[\"log_price\"].describe())\n",
                "\n",
                "# Check for missing values\n",
                "print(\"\\nMissing Values:\")\n",
                "print(\"=\" * 50)\n",
                "missing_info = df.isnull().sum()\n",
                "missing_info = missing_info[missing_info > 0].sort_values(ascending=False)\n",
                "print(missing_info)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4a12732",
            "metadata": {},
            "source": [
                "### Verdeling van de target variabele `log_price`\n",
                "De log-transformatie zorgt voor een meer symmetrische verdeling. Bij lagere prijzen zijn verschillen van een bepaalde grootte belangrijker dan in de hogere regionen. De log-transformatie vertaalt dit naar de numerieke schaal van de target variabele."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e4e06baf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Histogram of log prices\n",
                "fig = px.histogram(\n",
                "    df,\n",
                "    x=\"log_price\",\n",
                "    nbins=50,\n",
                "    title=\"Distribution of Log-Transformed Airbnb Prices\",\n",
                "    labels={\"log_price\": \"Log Price\", \"count\": \"Number of Listings\"},\n",
                "    opacity=0.7,\n",
                "    marginal=\"box\",  # Add box plot on top\n",
                ")\n",
                "\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "\n",
                "fig.show()\n",
                "\n",
                "# Calculate actual price statistics (inverse log transformation)\n",
                "df[\"price\"] = np.exp(df[\"log_price\"])\n",
                "print(\"Actual Price Statistics:\")\n",
                "print(f\"Mean: ${df.price.mean():.2f}\")\n",
                "print(f\"Median: ${df.price.median():.2f}\")\n",
                "print(f\"Min: ${df.price.min():.2f}\")\n",
                "print(f\"Max: ${df.price.max():.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a598b3e7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Histogram of actual prices\n",
                "fig = px.histogram(\n",
                "    df,\n",
                "    x=\"price\",\n",
                "    nbins=50,\n",
                "    title=\"Distribution of Actual Airbnb Prices\",\n",
                "    labels={\"price\": \"Actual Price\", \"count\": \"Number of Listings\"},\n",
                "    opacity=0.7,\n",
                "    marginal=\"box\",  # Add box plot on top\n",
                ")\n",
                "\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "558230e5",
            "metadata": {},
            "source": [
                "### Categorische features\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4a97813c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Room type distribution\n",
                "room_type_counts = df[\"room_type\"].value_counts()\n",
                "\n",
                "fig = px.bar(\n",
                "    x=room_type_counts.index,\n",
                "    y=room_type_counts.values,\n",
                "    title=\"Distribution of Room Types\",\n",
                "    labels={\"x\": \"Room Type\", \"y\": \"Count\"},\n",
                "    color=room_type_counts.index,\n",
                "    text=room_type_counts.values,\n",
                ")\n",
                "\n",
                "fig.update_traces(texttemplate=\"%{text:.0f}\", textposition=\"outside\")\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "fig.show()\n",
                "\n",
                "# Property type distribution\n",
                "property_type_counts = df[\"property_type\"].value_counts().head(10)\n",
                "\n",
                "fig = px.bar(\n",
                "    x=property_type_counts.index,\n",
                "    y=property_type_counts.values,\n",
                "    title=\"Top 10 Property Types\",\n",
                "    labels={\"x\": \"Property Type\", \"y\": \"Count\"},\n",
                "    color=property_type_counts.index,\n",
                "    text=property_type_counts.values,\n",
                ")\n",
                "\n",
                "fig.update_traces(texttemplate=\"%{text:.0f}\", textposition=\"outside\")\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "fig.update_xaxes(tickangle=45)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f57a48f5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# City distribution\n",
                "city_counts = df[\"city\"].value_counts()\n",
                "\n",
                "fig = px.bar(\n",
                "    x=city_counts.index,\n",
                "    y=city_counts.values,\n",
                "    title=\"Distribution of Listings by City\",\n",
                "    labels={\"x\": \"City\", \"y\": \"Number of Listings\"},\n",
                "    color=city_counts.index,\n",
                "    text=city_counts.values,\n",
                ")\n",
                "\n",
                "fig.update_traces(texttemplate=\"%{text:.0f}\", textposition=\"outside\")\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "fig.show()\n",
                "\n",
                "# Average price by city\n",
                "city_avg_price = df.groupby(\"city\")[\"log_price\"].mean().sort_values(ascending=False)\n",
                "\n",
                "fig = px.bar(\n",
                "    x=city_avg_price.index,\n",
                "    y=city_avg_price.values,\n",
                "    title=\"Average Log Price by City\",\n",
                "    labels={\"x\": \"City\", \"y\": \"Average Log Price\"},\n",
                "    color=city_avg_price.values,\n",
                "    color_continuous_scale=\"Viridis\",\n",
                "    text=[f\"{val:.3f}\" for val in city_avg_price.values],\n",
                ")\n",
                "\n",
                "fig.update_traces(texttemplate=\"%{text}\", textposition=\"outside\")\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8159c39d",
            "metadata": {},
            "source": [
                "### Geografische analyse"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "81edbe6d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_price_map(city_name, df_sample):\n",
                "    \"\"\"Create an interactive map showing Airbnb prices for a specific city.\"\"\"\n",
                "    # Sample data for performance (use fraction based on city size)\n",
                "    sample_frac = 0.3 if city_name in [\"NYC\", \"LA\"] else 0.8\n",
                "\n",
                "    city_data = df_sample[df_sample[\"city\"] == city_name].sample(frac=sample_frac, random_state=42)\n",
                "\n",
                "    # Create the map\n",
                "    fig = px.scatter_map(\n",
                "        city_data,\n",
                "        lat=\"latitude\",\n",
                "        lon=\"longitude\",\n",
                "        color=\"log_price\",\n",
                "        color_continuous_scale=\"Viridis\",\n",
                "        range_color=[df[\"log_price\"].min(), df[\"log_price\"].max()],\n",
                "        hover_data={\n",
                "            \"log_price\": \":.3f\",\n",
                "            \"room_type\": True,\n",
                "            \"bedrooms\": True,\n",
                "            \"neighbourhood\": True,\n",
                "        },\n",
                "        title=f\"Airbnb Prices in {city_name}\",\n",
                "        labels={\"log_price\": \"Log Price\", \"room_type\": \"Room Type\"},\n",
                "        zoom=10,\n",
                "        height=600,\n",
                "    )\n",
                "\n",
                "    fig.update_layout(\n",
                "        mapbox_style=\"open-street-map\",\n",
                "        coloraxis_colorbar={\n",
                "            \"title\": \"Log Price\",\n",
                "            \"thicknessmode\": \"pixels\",\n",
                "            \"thickness\": 30,\n",
                "            \"lenmode\": \"fraction\",\n",
                "            \"len\": 0.8,\n",
                "        },\n",
                "    )\n",
                "\n",
                "    return fig\n",
                "\n",
                "\n",
                "# Create maps for major cities\n",
                "cities_to_visualize = [\"NYC\", \"LA\", \"Chicago\", \"Boston\"]\n",
                "\n",
                "for city in cities_to_visualize:\n",
                "    if city in df[\"city\"].unique():\n",
                "        fig = create_price_map(city, df)\n",
                "        fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42f17f78",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "96f9bd87",
            "metadata": {},
            "source": [
                "### Numerieke features: Correlatie analyse"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5a2b068",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select numerical columns for correlation analysis\n",
                "numerical_cols = [\n",
                "    \"log_price\",\n",
                "    \"bedrooms\",\n",
                "    \"bathrooms\",\n",
                "    \"review_scores_rating\",\n",
                "    \"number_of_reviews\",\n",
                "    \"beds\",\n",
                "]\n",
                "\n",
                "# Calculate correlation matrix\n",
                "corr_matrix = df[numerical_cols].corr()\n",
                "\n",
                "# Create heatmap\n",
                "fig = px.imshow(\n",
                "    corr_matrix,\n",
                "    text_auto=True,\n",
                "    aspect=\"auto\",\n",
                "    title=\"Correlation Heatmap of Numerical Features\",\n",
                "    color_continuous_scale=\"RdBu_r\",\n",
                "    zmin=-1,\n",
                "    zmax=1,\n",
                ")\n",
                "\n",
                "fig.update_layout(height=800, width=800)\n",
                "fig.show()\n",
                "\n",
                "# Show correlation with target variable\n",
                "target_corr = corr_matrix[\"log_price\"].drop(\"log_price\").sort_values(ascending=False)\n",
                "\n",
                "fig = px.bar(\n",
                "    x=target_corr.index,\n",
                "    y=target_corr.values,\n",
                "    title=\"Feature Correlation with Log Price\",\n",
                "    labels={\"x\": \"Feature\", \"y\": \"Correlation Coefficient\"},\n",
                "    color=target_corr.values,\n",
                "    color_continuous_scale=\"RdBu_r\",\n",
                "    text=[f\"{val:.3f}\" for val in target_corr.values],\n",
                ")\n",
                "\n",
                "fig.update_traces(texttemplate=\"%{text}\", textposition=\"outside\")\n",
                "fig.update_layout(showlegend=False, height=500)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5915a2d",
            "metadata": {},
            "source": [
                "## _Data preparation_\n",
                "\n",
                "### _Missing values_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5457497f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Bathrooms - Fill with median (1.0 is most common)\n",
                "print(f\"Bathrooms missing: {df['bathrooms'].isnull().sum()}\")\n",
                "print(f\"Bathrooms distribution:\\n{df['bathrooms'].value_counts()}\")\n",
                "df[\"bathrooms\"] = df[\"bathrooms\"].fillna(1.0)\n",
                "print(f\"After filling: {df['bathrooms'].isnull().sum()} missing\\n\")\n",
                "\n",
                "# 2. Review scores - Fill with 0 (indicates no reviews)\n",
                "print(f\"Review scores missing: {df['review_scores_rating'].isnull().sum()}\")\n",
                "print(f\"Review scores distribution:\\n{df['review_scores_rating'].value_counts().head()}\")\n",
                "df[\"review_scores_rating\"] = df[\"review_scores_rating\"].fillna(0)\n",
                "print(f\"After filling: {df['review_scores_rating'].isnull().sum()} missing\\n\")\n",
                "\n",
                "# 3. Bedrooms - Fill with median (1.0 is most common)\n",
                "print(f\"Bedrooms missing: {df['bedrooms'].isnull().sum()}\")\n",
                "df[\"bedrooms\"] = df[\"bedrooms\"].fillna(1.0)\n",
                "print(f\"After filling: {df['bedrooms'].isnull().sum()} missing\\n\")\n",
                "\n",
                "# 4. Beds - Fill with median (1.0 is most common)\n",
                "print(f\"Beds missing: {df['beds'].isnull().sum()}\")\n",
                "df[\"beds\"] = df[\"beds\"].fillna(1.0)\n",
                "print(f\"After filling: {df['beds'].isnull().sum()} missing\\n\")\n",
                "\n",
                "# 5. Host response rate - Fill with mean\n",
                "print(f\"Host response rate missing: {df['host_response_rate'].isnull().sum()}\")\n",
                "if df[\"host_response_rate\"].isnull().sum() > 0:\n",
                "    # Convert percentage strings to numeric\n",
                "    df[\"host_response_rate\"] = df[\"host_response_rate\"].apply(\n",
                "        lambda x: float(str(x).rstrip(\"%\")) / 100 if pd.notnull(x) and isinstance(x, str) else x\n",
                "    )\n",
                "    mean_response_rate = df[\"host_response_rate\"].mean()\n",
                "    df[\"host_response_rate\"] = df[\"host_response_rate\"].fillna(mean_response_rate)\n",
                "    print(f\"After filling: {df['host_response_rate'].isnull().sum()} missing\\n\")\n",
                "\n",
                "# 6. Host has profile pic - Fill with mode\n",
                "print(f\"Host has profile pic missing: {df['host_has_profile_pic'].isnull().sum()}\")\n",
                "if df[\"host_has_profile_pic\"].isnull().sum() > 0:\n",
                "    mode_profile_pic = df[\"host_has_profile_pic\"].mode()[0]\n",
                "    df[\"host_has_profile_pic\"] = df[\"host_has_profile_pic\"].fillna(mode_profile_pic)\n",
                "    print(f\"After filling: {df['host_has_profile_pic'].isnull().sum()} missing\\n\")\n",
                "\n",
                "# 7. Host identity verified - Fill with mode\n",
                "print(f\"Host identity verified missing: {df['host_identity_verified'].isnull().sum()}\")\n",
                "if df[\"host_identity_verified\"].isnull().sum() > 0:\n",
                "    mode_identity_verified = df[\"host_identity_verified\"].mode()[0]\n",
                "    df[\"host_identity_verified\"] = df[\"host_identity_verified\"].fillna(mode_identity_verified)\n",
                "    print(f\"After filling: {df['host_identity_verified'].isnull().sum()} missing\\n\")\n",
                "\n",
                "print(\"Final missing values check:\")\n",
                "print(df.isnull().sum().sort_values(ascending=False).head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a84c6187",
            "metadata": {},
            "source": [
                "### Data types"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a71acc5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert boolean columns from 't/f' strings to 1/0 integers\n",
                "boolean_columns = [\n",
                "    \"cleaning_fee\",\n",
                "    \"instant_bookable\",\n",
                "    \"host_has_profile_pic\",\n",
                "    \"host_identity_verified\",\n",
                "]\n",
                "\n",
                "for col in boolean_columns:\n",
                "    print(f\"Converting {col}:\")\n",
                "    print(f\"Before: {df[col].unique()}\")\n",
                "    df[col] = df[col].map({\"t\": 1, \"f\": 0, True: 1, False: 0}).astype(int)\n",
                "    print(f\"After: {df[col].unique()}\")\n",
                "    print(f\"Data type: {df[col].dtype}\\n\")\n",
                "\n",
                "# Convert review scores from 0-100 scale to 0-1 scale\n",
                "print(\n",
                "    f\"Review scores range before: {df.review_scores_rating.min()} - {df.review_scores_rating.max()}\"\n",
                ")\n",
                "df[\"review_scores_rating\"] = df[\"review_scores_rating\"] / 100\n",
                "print(\n",
                "    f\"Review scores range after: {df.review_scores_rating.min()} - {df.review_scores_rating.max()}\"\n",
                ")\n",
                "\n",
                "# Normalize number of reviews (divide by max to get 0-1 scale)\n",
                "max_reviews = df.number_of_reviews.max()\n",
                "print(f\"Max reviews: {max_reviews}\")\n",
                "df[\"number_of_reviews\"] = df.number_of_reviews / max_reviews\n",
                "print(f\"Normalized reviews range: {df.number_of_reviews.min()} - {df.number_of_reviews.max()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e0edd846",
            "metadata": {},
            "source": [
                "## Feature engineering\n",
                "\n",
                "### Amenities\n",
                "Deze variabele bestaat uit een reeks van voorzieningen en is in die vorm niet bruikbaar. We zetten de meest frequente om naar binaire features (aan-/afwezig)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "23e5b6af",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.amenities.values[:3]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee549af7",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_amenities(amenities_str):\n",
                "    \"\"\"Extract individual amenities from the amenities string.\"\"\"\n",
                "    if pd.isna(amenities_str):\n",
                "        return []\n",
                "    # Remove quotes and braces, split by comma\n",
                "    amenities_list = re.sub(r'[\"{}]', \"\", amenities_str).split(\",\")\n",
                "    # Clean and filter out empty strings and translation missing\n",
                "    amenities_list = [\n",
                "        amenity.strip()\n",
                "        for amenity in amenities_list\n",
                "        if amenity.strip() and \"translation missing\" not in amenity\n",
                "    ]\n",
                "    return amenities_list\n",
                "\n",
                "\n",
                "# Extract all unique amenities across the dataset\n",
                "all_amenities = set()\n",
                "for amenities_str in df[\"amenities\"]:\n",
                "    all_amenities.update(extract_amenities(amenities_str))\n",
                "\n",
                "print(f\"Total unique amenities found: {len(all_amenities)}\")\n",
                "print(\"\\nTop 20 most common amenities:\")\n",
                "amenity_counts = {}\n",
                "for amenities_str in df[\"amenities\"]:\n",
                "    for amenity in extract_amenities(amenities_str):\n",
                "        amenity_counts[amenity] = amenity_counts.get(amenity, 0) + 1\n",
                "\n",
                "# Sort amenities by count and display top 20\n",
                "top_amenities = sorted(amenity_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
                "for amenity, count in top_amenities:\n",
                "    print(f\"- {amenity}: {count} listings ({count / len(df) * 100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "98f6ab37",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create binary features for top amenities\n",
                "top_amenities_list = [amenity for amenity, count in top_amenities[:15]]  # Top 15 amenities\n",
                "\n",
                "for amenity in top_amenities_list:\n",
                "    feature_name = (\n",
                "        f\"amenity_{amenity.lower().replace(' ', '_').replace('/', '_').replace('-', '_')}\"\n",
                "    )\n",
                "    df[feature_name] = df[\"amenities\"].apply(lambda x: 1 if amenity in str(x) else 0)\n",
                "\n",
                "print(f\"Added {len(top_amenities_list)} amenity features\")\n",
                "print(\"New columns:\", [col for col in df.columns if col.startswith(\"amenity_\")][:10])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d031ede7",
            "metadata": {},
            "source": [
                "### Categorische encodering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b3da600",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Property type: group rare categories\n",
                "print(\"Property type distribution:\")\n",
                "property_counts = df[\"property_type\"].value_counts()\n",
                "print(property_counts)\n",
                "\n",
                "# Group rare property types\n",
                "threshold = 300  # Group types with fewer than 300 listings\n",
                "rare_types = property_counts[property_counts < threshold].index\n",
                "df[\"property_type\"] = df[\"property_type\"].replace(rare_types, \"Other\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "569e9406",
            "metadata": {},
            "outputs": [],
            "source": [
                "# One-hot encoding\n",
                "categorical_columns = [\"cancellation_policy\", \"city\", \"property_type\", \"room_type\"]\n",
                "\n",
                "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
                "encoded_categorical = encoder.fit_transform(df[categorical_columns])\n",
                "\n",
                "# Get feature names\n",
                "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
                "\n",
                "# Create final DataFrame\n",
                "df_cat = pd.DataFrame(encoded_categorical, columns=feature_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "10219770",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bed type encoding (simplified)\n",
                "print(\"Bed type distribution:\")\n",
                "print(df[\"bed_type\"].value_counts())\n",
                "\n",
                "# Convert to binary: Real Bed (2) vs Other (1)\n",
                "df[\"bed_type\"] = (\n",
                "    df[\"bed_type\"]\n",
                "    .map({\"Real Bed\": 2, \"Futon\": 1, \"Pull-out Sofa\": 1, \"Airbed\": 1, \"Couch\": 1})\n",
                "    .fillna(1)\n",
                ")\n",
                "\n",
                "print(\"\\nConverted bed_type to ordinal scale (1-2):\")\n",
                "print(df[\"bed_type\"].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33806f76",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_cat.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f329564b",
            "metadata": {},
            "source": [
                "### Neighborbood pricing\n",
                "Nieuwe feature met ordinale buurt-specifieke prijs-niveaus"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "480799a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create price per bedroom feature\n",
                "df[\"price_per_bedroom\"] = df[\"log_price\"] / df[\"bedrooms\"]\n",
                "\n",
                "# Handle infinite values (division by zero)\n",
                "df[\"price_per_bedroom\"] = df[\"price_per_bedroom\"].replace([np.inf, -np.inf], np.nan)\n",
                "\n",
                "# Calculate average price per bedroom by neighborhood\n",
                "neighborhood_avg = df.groupby(\"neighbourhood\")[\"price_per_bedroom\"].mean()\n",
                "\n",
                "# Handle any remaining infinite values in neighborhood averages\n",
                "neighborhood_avg = neighborhood_avg.replace([np.inf, -np.inf], np.nan)\n",
                "neighborhood_avg = neighborhood_avg.fillna(neighborhood_avg.mean())\n",
                "\n",
                "print(\"Top 10 most expensive neighborhoods:\")\n",
                "print(neighborhood_avg.sort_values(ascending=False).head(10))\n",
                "print(\"\\nTop 10 least expensive neighborhoods:\")\n",
                "print(neighborhood_avg.sort_values(ascending=True).head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7bb01d47",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create neighborhood price level categories\n",
                "def categorize_neighborhood(price_per_bedroom):\n",
                "    \"\"\"Categorize neighborhoods into price levels.\"\"\"\n",
                "    if pd.isna(price_per_bedroom):\n",
                "        return 2  # Default to middle category\n",
                "\n",
                "    percentiles = neighborhood_avg.quantile([0.25, 0.5, 0.75])\n",
                "\n",
                "    if price_per_bedroom <= percentiles[0.25]:\n",
                "        return 1  # Low price area\n",
                "    if price_per_bedroom <= percentiles[0.75]:\n",
                "        return 2  # Medium price area\n",
                "    return 3  # High price area\n",
                "\n",
                "\n",
                "# Apply categorization\n",
                "df[\"neighborhood_price_level\"] = df[\"price_per_bedroom\"].map(lambda x: categorize_neighborhood(x))\n",
                "\n",
                "print(\"Neighborhood price level distribution:\")\n",
                "print(df[\"neighborhood_price_level\"].value_counts())\n",
                "\n",
                "# Clean up - remove temporary columns\n",
                "df = df.drop([\"price_per_bedroom\", \"neighbourhood\"], axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b987f5f8",
            "metadata": {},
            "source": [
                "### Finale data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a8e78f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols = [\n",
                "    \"log_price\",\n",
                "    \"accommodates\",\n",
                "    \"bathrooms\",\n",
                "    \"bed_type\",\n",
                "    \"city\",  # keep city in for now, to be used for stratified sampling (see below)\n",
                "    \"cleaning_fee\",\n",
                "    \"host_has_profile_pic\",\n",
                "    \"host_identity_verified\",\n",
                "    \"host_response_rate\",\n",
                "    \"instant_bookable\",\n",
                "    \"latitude\",\n",
                "    \"longitude\",\n",
                "    \"number_of_reviews\",\n",
                "    \"review_scores_rating\",\n",
                "    \"bedrooms\",\n",
                "    \"beds\",\n",
                "    \"amenity_wireless_internet\",\n",
                "    \"amenity_kitchen\",\n",
                "    \"amenity_heating\",\n",
                "    \"amenity_essentials\",\n",
                "    \"amenity_smoke_detector\",\n",
                "    \"amenity_air_conditioning\",\n",
                "    \"amenity_tv\",\n",
                "    \"amenity_shampoo\",\n",
                "    \"amenity_hangers\",\n",
                "    \"amenity_carbon_monoxide_detector\",\n",
                "    \"amenity_internet\",\n",
                "    \"amenity_laptop_friendly_workspace\",\n",
                "    \"amenity_washer\",\n",
                "    \"amenity_hair_dryer\",\n",
                "    \"amenity_dryer\",\n",
                "    \"neighborhood_price_level\",\n",
                "]\n",
                "\n",
                "df = pd.concat([df[cols], df_cat], axis=1)\n",
                "\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c43dcab5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create train+validation/test splits\n",
                "train_df, test_df = train_test_split(\n",
                "    df,\n",
                "    test_size=0.2,\n",
                "    random_state=42,\n",
                "    stratify=df[\"city\"],  # Stratify by city for balanced representation\n",
                ")\n",
                "\n",
                "print(f\"Training set shape: {train_df.shape}\")\n",
                "print(f\"Test set shape: {test_df.shape}\")\n",
                "print(f\"\\nSplit verification: {train_df.shape[0] + test_df.shape[0]} total samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "72d40910",
            "metadata": {},
            "outputs": [],
            "source": [
                "## Drop stratification column from features\n",
                "train_df = train_df.drop(\"city\", axis=1)\n",
                "X_train = train_df.loc[:, train_df.columns != \"log_price\"]\n",
                "y_train = train_df[\"log_price\"]\n",
                "print(f\"Training features shape: {X_train.shape}\")\n",
                "print(f\"Training target shape: {y_train.shape}\")\n",
                "\n",
                "test_df = test_df.drop(\"city\", axis=1)\n",
                "X_test = test_df.loc[:, test_df.columns != \"log_price\"]\n",
                "y_test = test_df[\"log_price\"]\n",
                "print(f\"Test features shape: {X_test.shape}\")\n",
                "print(f\"Test target shape: {y_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c81e7f4",
            "metadata": {},
            "source": [
                "## Model definition\n",
                "\n",
                "### Lineaire regressie"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2e335b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Linear Regression with cross-validation\n",
                "linear_model = LinearRegression()\n",
                "\n",
                "# 5-fold cross-validation\n",
                "cv_scores = cross_val_score(linear_model, X_train, y_train, cv=5, scoring=\"r2\")\n",
                "\n",
                "print(f\"Linear Regression Cross-Validation RÂ² Scores: {cv_scores}\")\n",
                "print(f\"Mean RÂ²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
                "\n",
                "# Train on full training set\n",
                "linear_model.fit(X_train, y_train)\n",
                "\n",
                "# Feature importance (coefficients)\n",
                "feature_importance = pd.DataFrame(\n",
                "    {\"feature\": X_train.columns, \"importance\": linear_model.coef_}\n",
                ").sort_values(\"importance\", key=abs, ascending=False)\n",
                "\n",
                "print(\"\\nTop 10 Most Important Features (Linear Regression):\")\n",
                "print(feature_importance.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c008bba6",
            "metadata": {},
            "source": [
                "### Ridge regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "60d5e87b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ridge Regression with cross-validation\n",
                "ridge_model = Ridge(alpha=1.0)  # Alpha controls regularization strength\n",
                "\n",
                "cv_scores_ridge = cross_val_score(ridge_model, X_train, y_train, cv=5, scoring=\"r2\")\n",
                "\n",
                "print(f\"Ridge Regression Cross-Validation RÂ² Scores: {cv_scores_ridge}\")\n",
                "print(f\"Mean RÂ²: {cv_scores_ridge.mean():.4f} (+/- {cv_scores_ridge.std() * 2:.4f})\")\n",
                "\n",
                "# Compare with Linear Regression\n",
                "print(\"\\nModel Comparison:\")\n",
                "print(f\"Linear Regression: {cv_scores.mean():.4f}\")\n",
                "print(f\"Ridge Regression:  {cv_scores_ridge.mean():.4f}\")\n",
                "print(f\"Difference: {cv_scores_ridge.mean() - cv_scores.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7dfb24c6",
            "metadata": {},
            "source": [
                "### XGBoost Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9346af1d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost with cross-validation\n",
                "xgb_model = xgb.XGBRegressor(random_state=42, n_estimators=100, learning_rate=0.1, max_depth=6)\n",
                "\n",
                "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring=\"r2\")\n",
                "\n",
                "print(f\"XGBoost Cross-Validation RÂ² Scores: {cv_scores_xgb}\")\n",
                "print(f\"Mean RÂ²: {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std() * 2:.4f})\")\n",
                "\n",
                "# Compare all models\n",
                "print(\"\\nFinal Model Comparison:\")\n",
                "print(f\"Linear Regression: {cv_scores.mean():.4f}\")\n",
                "print(f\"Ridge Regression:  {cv_scores_ridge.mean():.4f}\")\n",
                "print(f\"XGBoost:          {cv_scores_xgb.mean():.4f}\")\n",
                "\n",
                "# Train final model on full training data\n",
                "xgb_model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c7c89fb5",
            "metadata": {},
            "source": [
                "#### Scoring"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "10ce6c5c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions on validation set\n",
                "test_predictions = xgb_model.predict(X_test)\n",
                "\n",
                "# Calculate metrics\n",
                "mae = mean_absolute_error(y_test, test_predictions)\n",
                "mse = mean_squared_error(y_test, test_predictions)\n",
                "rmse = np.sqrt(mse)\n",
                "r2 = r2_score(y_test, test_predictions)\n",
                "\n",
                "print(\"Validation Set Performance:\")\n",
                "print(f\"MAE:  {mae:.4f}\")\n",
                "print(f\"MSE:  {mse:.4f}\")\n",
                "print(f\"RMSE: {rmse:.4f}\")\n",
                "print(f\"RÂ²:   {r2:.4f}\")\n",
                "\n",
                "# Convert back to actual prices for interpretation\n",
                "y_val_actual = np.exp(y_test)\n",
                "val_predictions_actual = np.exp(test_predictions)\n",
                "mae_actual = mean_absolute_error(y_val_actual, val_predictions_actual)\n",
                "\n",
                "print(\"\\nIn actual dollars:\")\n",
                "print(f\"Mean actual price: ${y_val_actual.mean():.2f}\")\n",
                "print(f\"MAE in dollars: ${mae_actual:.2f}\")\n",
                "print(f\"This means our model is off by about ${mae_actual:.2f} on average\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b2b94721",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance from XGBoost\n",
                "feature_importance = pd.DataFrame(\n",
                "    {\"feature\": X_train.columns, \"importance\": xgb_model.feature_importances_}\n",
                ").sort_values(\"importance\", ascending=False)\n",
                "\n",
                "# Plot top 15 most important features\n",
                "top_features = feature_importance.head(15)\n",
                "\n",
                "fig = px.bar(\n",
                "    x=top_features[\"importance\"],\n",
                "    y=top_features[\"feature\"],\n",
                "    orientation=\"h\",\n",
                "    title=\"Top 15 Most Important Features (XGBoost)\",\n",
                "    labels={\"x\": \"Feature Importance\", \"y\": \"Feature\"},\n",
                "    text=[f\"{val:.4f}\" for val in top_features[\"importance\"]],\n",
                ")\n",
                "\n",
                "fig.update_traces(texttemplate=\"%{text}\", textposition=\"outside\")\n",
                "fig.update_layout(height=600, yaxis={\"categoryorder\": \"total ascending\"})\n",
                "fig.show()\n",
                "\n",
                "print(\"\\nBusiness Insights from Feature Importance:\")\n",
                "for i, row in top_features.head(10).iterrows():\n",
                "    print(f\"{i + 1}. {row['feature']}: {row['importance']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9b14fb63",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create prediction vs actual plot\n",
                "fig = px.scatter(\n",
                "    x=y_test,\n",
                "    y=test_predictions,\n",
                "    title=\"Predicted vs Actual Log Prices (Test Set)\",\n",
                "    labels={\"x\": \"Actual Log Price\", \"y\": \"Predicted Log Price\"},\n",
                "    trendline=\"ols\",\n",
                "    opacity=0.6,\n",
                ")\n",
                "\n",
                "# Add perfect prediction line\n",
                "fig.add_trace(\n",
                "    go.Scatter(\n",
                "        x=[y_test.min(), y_test.max()],\n",
                "        y=[y_test.min(), y_test.max()],\n",
                "        mode=\"lines\",\n",
                "        name=\"Perfect Prediction\",\n",
                "        line={\"color\": \"red\", \"dash\": \"dash\"},\n",
                "    )\n",
                ")\n",
                "\n",
                "fig.update_layout(height=500, width=800)\n",
                "fig.show()\n",
                "\n",
                "# Residual plot\n",
                "residuals = y_test - test_predictions\n",
                "\n",
                "fig = px.scatter(\n",
                "    x=test_predictions,\n",
                "    y=residuals,\n",
                "    title=\"Residual Plot (Test Set)\",\n",
                "    labels={\"x\": \"Predicted Log Price\", \"y\": \"Residual (Actual - Predicted)\"},\n",
                "    opacity=0.6,\n",
                ")\n",
                "\n",
                "# Add zero line\n",
                "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")\n",
                "fig.update_layout(height=500, width=800)\n",
                "fig.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ml-courses",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
