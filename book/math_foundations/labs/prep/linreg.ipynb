{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdd24c6",
   "metadata": {},
   "source": [
    "# Lineaire Regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece2cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7a4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Download data from kaggle\n",
    "path = kagglehub.dataset_download(\"yashdevladdha/uber-ride-analytics-dashboard\")\n",
    "\n",
    "# Load data into Pandas DataFrame\n",
    "csv_file = os.path.join(path, \"ncr_ride_bookings.csv\")\n",
    "df = pd.read_csv(csv_file)\n",
    "print(\"✅ Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb31fd",
   "metadata": {},
   "source": [
    "- Target variabele $\\pmb{y}$:  \n",
    "    - `Avg CTAT`\n",
    "- Features $\\pmb{X}$:\n",
    "    - `Avg VTAT`\n",
    "    - `Booking Value`\n",
    "    - `Ride Distance`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c085156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.loc[:, (\"Avg CTAT\", \"Avg VTAT\", \"Booking Value\", \"Ride Distance\")]\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae6a92",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Maak NumPy array aan voor de target $\\pmb{y}$ mèt _standaardschaling_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71589b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Avg CTAT\"].values\n",
    "\n",
    "y_mean = np.mean(y)\n",
    "y_std = np.std(y)\n",
    "y_scaled = (y - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b91bde",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Maak NumPy array aan voor de featurematrix $\\pmb{X}$ mèt _standaardschaling_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f03250",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = df[[\"Avg VTAT\", \"Booking Value\", \"Ride Distance\"]].values\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a bias term\n",
    "X_scaled = np.column_stack([np.ones(X_scaled.shape[0]), X_scaled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9f685",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Maak random 80/20% train/test split van $\\pmb{y}$ en $\\pmb{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278b3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 81600\n",
      "Test set size: 20400\n",
      "Training set shape: X=(81600, 4), y=(81600,)\n",
      "Test set shape: X=(20400, 4), y=(20400,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c7d29",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Hoe is het gesteld met het conditienummer van de _training_ design matrix en de multicollineariteit bij de predictoren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24dd530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of training design matrix: 1.07\n",
      "\n",
      "Interpretation:\n",
      "- Excellent: Matrix is well-conditioned\n"
     ]
    }
   ],
   "source": [
    "condition_number = np.linalg.cond(X_train)\n",
    "print(f\"Condition number of training design matrix: {condition_number:.2f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "if condition_number < 10:\n",
    "    print(\"- Excellent: Matrix is well-conditioned\")\n",
    "elif condition_number < 100:\n",
    "    print(\"- Good: Matrix is reasonably well-conditioned\")\n",
    "elif condition_number < 1000:\n",
    "    print(\"- Fair: Some numerical instability may occur\")\n",
    "else:\n",
    "    print(\"- Poor: Matrix is ill-conditioned, results may be unreliable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce1573",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "\n",
    "Implementeer de **manuele** analytische oplossing voor de parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df17a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed-form OLS coefficients:\n",
      "  β₀ (bias):        0.001998\n",
      "  β₁ (Avg VTAT):    0.055260\n",
      "  β₂ (Booking Value):    0.000572\n",
      "  β₃ (Ride Distance): 0.099276\n"
     ]
    }
   ],
   "source": [
    "def closed_form_ols(X, y):\n",
    "    \"\"\"\n",
    "    Compute OLS coefficients using the closed-form solution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "        Design matrix including bias term\n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Target vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    beta : ndarray, shape (n_features,)\n",
    "        Estimated coefficients\n",
    "    \"\"\"\n",
    "    XtX = X.T @ X\n",
    "    Xty = X.T @ y\n",
    "    beta = np.linalg.inv(XtX) @ Xty\n",
    "    return beta\n",
    "\n",
    "\n",
    "# Calculate coefficients\n",
    "beta_closed = closed_form_ols(X_train, y_train)\n",
    "\n",
    "print(\"Closed-form OLS coefficients:\")\n",
    "print(f\"  β₀ (bias):        {beta_closed[0]:.6f}\")\n",
    "print(f\"  β₁ (Avg VTAT):    {beta_closed[1]:.6f}\")\n",
    "print(f\"  β₂ (Booking Value):    {beta_closed[2]:.6f}\")\n",
    "print(f\"  β₃ (Ride Distance): {beta_closed[3]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edf484",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "\n",
    "Bereken de $R^2$ score op de _test_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a40f499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Closed-form OLS R² on test set: 0.0126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred_test = X_test @ beta_closed\n",
    "r2_closed = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nClosed-form OLS R² on test set: {r2_closed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8ccd1",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "\n",
    "Implementeer de **manuele** _gradient descent_ oplossing voor de parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5ac40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1000, Loss: 0.999292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/1000, Loss: 0.985887\n",
      "Iteration 200/1000, Loss: 0.985688\n",
      "Iteration 300/1000, Loss: 0.985685\n",
      "Iteration 400/1000, Loss: 0.985685\n",
      "Iteration 500/1000, Loss: 0.985685\n",
      "Iteration 600/1000, Loss: 0.985685\n",
      "Iteration 700/1000, Loss: 0.985685\n",
      "Iteration 800/1000, Loss: 0.985685\n",
      "Iteration 900/1000, Loss: 0.985685\n",
      "Iteration 1000/1000, Loss: 0.985685\n",
      "\n",
      "Final parameters: {b}\n",
      "\n",
      "Comparison with closed-form OLS:\n",
      "  β₀: GD=0.001998, OLS=0.001998\n",
      "  β₁: GD=0.055260, OLS=0.055260\n",
      "  β₂: GD=0.000572, OLS=0.000572\n",
      "  β₃: GD=0.099276, OLS=0.099276\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([0.0, 0.0, 0.0, 0.0], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Training loop\n",
    "n_iterations = 1000\n",
    "learning_rate = 0.01\n",
    "loss_history = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Forward pass: compute predictions\n",
    "    y_pred = X_tensor @ b\n",
    "\n",
    "    # Compute loss (Mean Squared Error)\n",
    "    loss = torch.mean((y_tensor - y_pred) ** 2)\n",
    "\n",
    "    # Backward pass: compute gradients (autograd!)\n",
    "    loss.backward()  # Compute gradients via backpropagation\n",
    "\n",
    "    # Update parameters\n",
    "    with torch.no_grad():  # Disable gradient tracking for parameter update\n",
    "        b -= learning_rate * b.grad\n",
    "\n",
    "    # Zero gradients for next iteration (crucial!)\n",
    "    b.grad.zero_()\n",
    "\n",
    "    # Store loss for visualization\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    if (i + 1) % 100 == 0 or i == 0:\n",
    "        print(f\"Iteration {i + 1}/{n_iterations}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "# Extract learned parameters\n",
    "print(\"\\nFinal parameters: {b}\")\n",
    "print(\"\\nComparison with closed-form OLS:\")\n",
    "print(f\"  β₀: GD={b[0].item():.6f}, OLS={beta_closed[0]:.6f}\")\n",
    "print(f\"  β₁: GD={b[1].item():.6f}, OLS={beta_closed[1]:.6f}\")\n",
    "print(f\"  β₂: GD={b[2].item():.6f}, OLS={beta_closed[2]:.6f}\")\n",
    "print(f\"  β₃: GD={b[3].item():.6f}, OLS={beta_closed[3]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca2540",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "\n",
    "Implementeer de **manuele** _maximum likelihood_ schatting voor de normaal verdeelde ruis parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b247994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated standard deviation of residuals: 0.992841\n"
     ]
    }
   ],
   "source": [
    "residuals = y_train - X_train @ beta_closed\n",
    "\n",
    "N = len(y_train)\n",
    "M = 4  # number of parameters (intercept + 3 slopes)\n",
    "sigma_hat = np.sqrt(np.sum(residuals**2) / (N - M))\n",
    "print(f\"\\nEstimated standard deviation of residuals: {sigma_hat:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d446dc8",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "\n",
    "Bereken de 95% betrouwbaarheidsintervallen voor $b_0$, $b_1$, $b_2$ en $b_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4700820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "95% Confidence Intervals:\n",
      "  b0: [-0.005, 0.009]\n",
      "  b1: [0.048, 0.062]\n",
      "  b2: [-0.006, 0.007]\n",
      "  b3: [0.092, 0.106]\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard errors\n",
    "# SE(b_j) = σ * sqrt([(X^T X)^{-1}]_{jj})\n",
    "XtX_inv = np.linalg.inv(X_train.T @ X_train)\n",
    "se_b = sigma_hat * np.sqrt(np.diag(XtX_inv))\n",
    "\n",
    "# 95% confidence intervals using t-distribution\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha / 2, df=N - M)\n",
    "\n",
    "ci_lower = beta_closed - t_critical * se_b\n",
    "ci_upper = beta_closed + t_critical * se_b\n",
    "\n",
    "print(\"\\n95% Confidence Intervals:\")\n",
    "print(f\"  b0: [{ci_lower[0]:.3f}, {ci_upper[0]:.3f}]\")\n",
    "print(f\"  b1: [{ci_lower[1]:.3f}, {ci_upper[1]:.3f}]\")\n",
    "print(f\"  b2: [{ci_lower[2]:.3f}, {ci_upper[2]:.3f}]\")\n",
    "print(f\"  b3: [{ci_lower[3]:.3f}, {ci_upper[3]:.3f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
