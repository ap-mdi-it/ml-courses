{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68bf597",
   "metadata": {},
   "source": [
    "# Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71664f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Feedforward Neural Network with one hidden layer.\n",
    "\n",
    "    Architecture:\n",
    "    - Input layer: n_features neurons\n",
    "    - Hidden layer: n_hidden neurons (ReLU activation)\n",
    "    - Output layer: n_classes neurons (logits - no softmax, CrossEntropyLoss does this)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_features, n_hidden, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(n_features, n_hidden)  # Input to hidden\n",
    "        self.relu = nn.ReLU()  # ReLU activation\n",
    "        self.fc2 = nn.Linear(n_hidden, n_classes)  # Hidden to output\n",
    "\n",
    "        # Optional: Custom weight initialization (He initialization for ReLU)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        x = self.fc1(x)  # Linear transformation\n",
    "        x = self.relu(x)  # ReLU activation\n",
    "        x = self.fc2(x)  # Linear transformation (logits)\n",
    "        return x  # No softmax - CrossEntropyLoss handles it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c947263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27633276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Download data from kaggle\n",
    "path = kagglehub.dataset_download(\"yashdevladdha/uber-ride-analytics-dashboard\")\n",
    "\n",
    "# Load data into Pandas DataFrame\n",
    "csv_file = os.path.join(path, \"ncr_ride_bookings.csv\")\n",
    "df = pd.read_csv(csv_file)\n",
    "print(\"✅ Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a97bc",
   "metadata": {},
   "source": [
    "- Target variabele $\\pmb{y}$:  \n",
    "    - `Payment Method`\n",
    "- Features $\\pmb{X}$:\n",
    "    - `Avg VTAT`\n",
    "    - `Avg CTAT`\n",
    "    - `Booking Value`\n",
    "    - `Ride Distance` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a516602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.loc[:, (\"Payment Method\", \"Avg VTAT\", \"Avg CTAT\", \"Booking Value\", \"Ride Distance\")]\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e578f0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UPI' 'Debit Card' 'Cash' 'Uber Wallet' 'Credit Card']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Payment Method\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a096c2",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Maak NumPy array aan voor de target $\\pmb{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77796839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "y = df[\"Payment Method\"].values\n",
    "\n",
    "# Make a map to convert payment methods to integers\n",
    "payment_method_map = {method: idx for idx, method in enumerate(df[\"Payment Method\"].unique())}\n",
    "y = np.array([payment_method_map[method] for method in y])\n",
    "\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a49331",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Maak NumPy array aan voor de featurematrix $\\pmb{X}$ mèt _standaardschaling_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8653520",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = df[[\"Avg VTAT\", \"Avg CTAT\", \"Booking Value\", \"Ride Distance\"]].values\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7490bf8",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Maak random 80/20% train/test split van $\\pmb{y}$ en $\\pmb{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0836f973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 81600\n",
      "Test set size: 20400\n",
      "Training set shape: X=(81600, 4), y=(81600,)\n",
      "Test set shape: X=(20400, 4), y=(20400,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442e1a6",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Converteer $\\pmb{y}$ en $\\pmb{X}$ naar PyTorch formaat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbdd1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d47f02",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Train een `NeuralNetwork` model (zie hierboven) met 10 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "308113c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyTorch Neural Network Model Created!\n",
      "\n",
      "Model Architecture:\n",
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 105\n",
      "\n",
      "Parameter details:\n",
      "  fc1.weight: torch.Size([10, 4]) (40 parameters)\n",
      "  fc1.bias: torch.Size([10]) (10 parameters)\n",
      "  fc2.weight: torch.Size([5, 10]) (50 parameters)\n",
      "  fc2.bias: torch.Size([5]) (5 parameters)\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "n_features = X_train.shape[1]  # 4 features\n",
    "n_hidden = 10\n",
    "n_classes = len(payment_method_map)\n",
    "\n",
    "model = NeuralNetwork(n_features, n_hidden, n_classes).to(device)\n",
    "\n",
    "print(\"✓ PyTorch Neural Network Model Created!\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(\"\\nParameter details:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.shape} ({param.numel()} parameters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c7149",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Definieer de _Cross Entropy Loss_ functie en _Stochastic Gradient Descent_ als optimalisatiealgoritme (_learning rate_ = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daa86e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loss function and optimizer configured!\n",
      "\n",
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.02\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate: 0.02\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "print(\"✓ Loss function and optimizer configured!\")\n",
    "print(f\"\\nLoss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")\n",
    "print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff08ab",
   "metadata": {},
   "source": [
    "## ✍️\n",
    "Train the model for 2000 epochs and plot the test/training _loss_ en accuraatheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181f84c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network with PyTorch...\n",
      "Architecture: 4 → 10 (ReLU) → 5\n",
      "Learning rate: 0.02\n",
      "Epochs: 2000\n",
      "\n",
      "Training progress:\n",
      "----------------------------------------------------------------------\n",
      "Epoch    1 | Train Loss: 2.1648 | Test Loss: 2.1529 | Train Acc: 16.45% | Test Acc: 16.88%\n",
      "Epoch  200 | Train Loss: 1.4613 | Test Loss: 1.4589 | Train Acc: 43.11% | Test Acc: 43.03%\n",
      "Epoch  400 | Train Loss: 1.4191 | Test Loss: 1.4152 | Train Acc: 44.52% | Test Acc: 44.53%\n",
      "Epoch  600 | Train Loss: 1.4101 | Test Loss: 1.4062 | Train Acc: 44.86% | Test Acc: 44.89%\n",
      "Epoch  800 | Train Loss: 1.4059 | Test Loss: 1.4021 | Train Acc: 44.99% | Test Acc: 44.97%\n",
      "Epoch 1000 | Train Loss: 1.4034 | Test Loss: 1.3996 | Train Acc: 45.01% | Test Acc: 45.00%\n",
      "Epoch 1200 | Train Loss: 1.4017 | Test Loss: 1.3979 | Train Acc: 45.01% | Test Acc: 45.00%\n",
      "Epoch 1400 | Train Loss: 1.4005 | Test Loss: 1.3968 | Train Acc: 45.01% | Test Acc: 45.00%\n",
      "Epoch 1600 | Train Loss: 1.3996 | Test Loss: 1.3959 | Train Acc: 45.01% | Test Acc: 45.00%\n",
      "Epoch 1800 | Train Loss: 1.3989 | Test Loss: 1.3953 | Train Acc: 45.01% | Test Acc: 45.00%\n",
      "Epoch 2000 | Train Loss: 1.3984 | Test Loss: 1.3947 | Train Acc: 45.01% | Test Acc: 45.00%\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "✓ Training completed!\n",
      "\n",
      "Final Results:\n",
      "  Training Loss: 1.3984\n",
      "  Test Loss: 1.3947\n",
      "  Training Accuracy: 45.01%\n",
      "  Test Accuracy: 45.00%\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "n_epochs = 2000\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"Training Neural Network with PyTorch...\")\n",
    "print(f\"Architecture: {n_features} → {n_hidden} (ReLU) → {n_classes}\")\n",
    "print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"Epochs: {n_epochs}\")\n",
    "print(\"\\nTraining progress:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # ============ TRAINING MODE ============\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    # Forward pass\n",
    "    train_outputs = model(X_train_tensor)\n",
    "    train_loss = criterion(train_outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    train_loss.backward()  # Compute gradients (backpropagation!)\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # ============ EVALUATION MODE ============\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        # Training accuracy\n",
    "        _, train_predicted = torch.max(train_outputs, 1)\n",
    "        train_acc = (train_predicted == y_train_tensor).float().mean()\n",
    "\n",
    "        # Test loss and accuracy\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        _, test_predicted = torch.max(test_outputs, 1)\n",
    "        test_acc = (test_predicted == y_test_tensor).float().mean()\n",
    "\n",
    "    # Store history\n",
    "    train_losses.append(train_loss.item())\n",
    "    test_losses.append(test_loss.item())\n",
    "    train_accuracies.append(train_acc.item())\n",
    "    test_accuracies.append(test_acc.item())\n",
    "\n",
    "    # Print progress every 200 epochs\n",
    "    if (epoch + 1) % 200 == 0 or epoch == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1:4d} | \"\n",
    "            f\"Train Loss: {train_loss.item():.4f} | \"\n",
    "            f\"Test Loss: {test_loss.item():.4f} | \"\n",
    "            f\"Train Acc: {train_acc.item():.2%} | \"\n",
    "            f\"Test Acc: {test_acc.item():.2%}\"\n",
    "        )\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"\\n✓ Training completed!\")\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"  Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  Test Loss: {test_losses[-1]:.4f}\")\n",
    "print(f\"  Training Accuracy: {train_accuracies[-1]:.2%}\")\n",
    "print(f\"  Test Accuracy: {test_accuracies[-1]:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
