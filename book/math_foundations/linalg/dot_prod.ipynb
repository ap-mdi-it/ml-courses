{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6c7a6615",
            "metadata": {},
            "source": [
                "(target-dot-product)=\n",
                "# _Dot_ product\n",
                "Misschien wel de belangrijkste operatie in machine learning is het **_dot_** of _inner_ product tussen 2 vectoren uit dezelfde ruimte (dus met een gelijk aantal elementen).\n",
                "De eerste vector is daarbij een rij-vector $\\pmb{a}^T$ en de tweede een kolom-vector $\\pmb{b}$.\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\pmb{a}^T\\pmb{b} = \\pmb{a}'\\pmb{b} &= \\pmb{a}.\\pmb{b} \\\\\n",
                "&= \\sum_{i=1}^{n}a_ib_i \\\\\n",
                "&= \\begin{bmatrix}\n",
                "a_1 & a_2 \\ldots & a_n\n",
                "\\end{bmatrix}\\begin{bmatrix}\n",
                "b_1 \\cr\n",
                "b_2 \\cr\n",
                "\\vdots  \\cr\n",
                "b_n\n",
                "\\end{bmatrix} \\\\\n",
                "&= a_1b_1 + a_2b_2 + \\ldots + a_nb_n\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "**Het dot product tussen 2 vectoren uit een gegeven ruimte, is dus de som van de elementgewijze producten. Het resultaat is altijd een scalaire waarde.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "3181d7ee",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "d4af08fb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dot product result: 32\n"
                    ]
                }
            ],
            "source": [
                "a = np.array([1, 2, 3])\n",
                "b = np.array([4, 5, 6])\n",
                "print(f\"Dot product result: {np.dot(a, b)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "e23621a8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "np.int64(32)"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a[0] * b[0] + a[1] * b[1] + a[2] * b[2]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "b0c874a6",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "np.int64(32)"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# alternative notation for np.dot\n",
                "a @ b"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "788860b0",
            "metadata": {},
            "source": [
                "Merk op dat:\n",
                "\n",
                "$$\n",
                "\\pmb{a}^T\\pmb{b} = \\pmb{b}^T\\pmb{a}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "72384ba0",
            "metadata": {},
            "source": [
                "  Het principe van het _dot_ product kan uitgebreid worden naar het geval een matrix en een vector uit dezelfde ruimte: $\\pmb{A}\\pmb{b}$.\n",
                "Geometrisch moet de matrix $\\pmb{A}$ hier gezien worden als een verzameling van punten in dezelfde ruimte als waar $\\pmb{b}$ uit afkomstig is.\n",
                "$\\pmb{A}$ heeft dus evenveel _kolommen_ als er elementen in $\\pmb{b}$ zijn.\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\pmb{A}\\pmb{b} &= \\begin{bmatrix}\n",
                "\\sum_{i=1}^{n}A_{1,i}b_i \\cr\n",
                "\\sum_{i=1}^{n}A_{2,i}b_i \\cr\n",
                "\\vdots  \\cr\n",
                "\\sum_{i=1}^{n}A_{m,i}b_i\n",
                "\\end{bmatrix} \\\\\n",
                "&= \\begin{bmatrix}\n",
                "A_{1,1} & A_{1,2} & \\ldots & A_{1,n} \\cr\n",
                "A_{2,1} & A_{2,2} & \\ldots & A_{2,n} \\cr\n",
                "\\vdots & \\vdots & \\ldots & \\vdots \\cr\n",
                "A_{m,1} & A_{m,2} & \\ldots & A_{m,n}\n",
                "\\end{bmatrix}\\begin{bmatrix}\n",
                "b_1 \\cr\n",
                "b_2 \\cr\n",
                "\\vdots  \\cr\n",
                "b_n\n",
                "\\end{bmatrix} \\\\\n",
                "&= \\begin{bmatrix}\n",
                "A_{1,1}b_1 + A_{1,2}b_2 + \\ldots + A_{1,n}b_n \\cr\n",
                "A_{2,1}b_1 + A_{2,2}b_2 + \\ldots + A_{2,n}b_n \\cr\n",
                "\\vdots \\cr\n",
                "A_{m,1}b_1 + A_{m,2}b_2 + \\ldots + A_{m,n}b_n\n",
                "\\end{bmatrix}\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "**Bij het dot product tussen een matrix en een vector, is resultaat altijd een vector met evenveel elementen als er _rijen_ zijn in de matrix.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "acc754e6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Matrix A shape: (2, 3)\n",
                        "Matrix A has 2 rows and 3 columns.\n",
                        "Dot product result:\n",
                        "[32 77]\n"
                    ]
                }
            ],
            "source": [
                "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
                "print(f\"Matrix A shape: {A.shape}\")\n",
                "nrow, ncol = A.shape\n",
                "print(f\"Matrix A has {nrow} rows and {ncol} columns.\")\n",
                "print(f\"Dot product result:\\n{np.dot(A, b)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "169f2f01",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([32, 77])"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.array(\n",
                "    [\n",
                "        A[0, 0] * b[0] + A[0, 1] * b[1] + A[0, 2] * b[2],\n",
                "        A[1, 0] * b[0] + A[1, 1] * b[1] + A[1, 2] * b[2],\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "4b1419b5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([32, 77])"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# alternative notation for np.dot\n",
                "A @ b"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c3edd995",
            "metadata": {},
            "source": [
                ":::{warning}\n",
                "$$\n",
                "\\pmb{A}\\pmb{b} \\neq \\pmb{b}\\pmb{A}\n",
                "$$\n",
                ":::"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "07d46061",
            "metadata": {},
            "source": [
                "Tenslotte bespreken we ook nog het geval van de uitbreiding naar 2 matrices; het _inner product_ $\\pmb{A}\\pmb{B}^T$.\n",
                "Geometrisch kunnen we beide matrices zien als verzamelingen van punten in dezelfde $n$-dimensionele ruimte. Ze hebben hetzelfde aantal kolommen, maar niet per se hetzelfde aantal rijen.\n",
                "Meestal wordt $\\pmb{B}$ direct gezien als een matrix met $n$ rijen en een bepaald aantal kolommen $p$. Dan wordt de notatie simpelweg $\\pmb{A}\\pmb{B}$.\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\pmb{A}\\pmb{B} &= \\begin{bmatrix}\n",
                "A_{1,1} & A_{1,2} & \\ldots & A_{1,n} \\cr\n",
                "A_{2,1} & A_{2,2} & \\ldots & A_{2,n} \\cr\n",
                "\\vdots & \\vdots & \\ldots & \\vdots \\cr\n",
                "A_{m,1} & A_{m,2} & \\ldots & A_{m,n}\n",
                "\\end{bmatrix}\\begin{bmatrix}\n",
                "B_{1,1} & B_{1,2} \\ldots & B_{1,p} \\cr\n",
                "B_{2,1} & B_{2,2} \\ldots & B_{2,p} \\cr\n",
                "\\vdots & \\vdots \\ldots & \\vdots \\cr\n",
                "B_{n,1} & B_{n,2} \\ldots & B_{n,p}\n",
                "\\end{bmatrix} \\\\\n",
                "&= \\begin{bmatrix}\n",
                "A_{1,1}B_{1,1} + A_{1,2}B_{2,1} + \\ldots + A_{1,n}B_{n,1} & A_{1,1}B_{1,2} + A_{1,2}B_{2,2} + \\ldots + A_{1,n}B_{n,2} & \\ldots & A_{1,1}B_{1,p} + A_{1,2}B_{2,p} + \\ldots + A_{1,n}B_{n,p} \\cr\n",
                "A_{2,1}B_{1,1} + A_{2,2}B_{2,1} + \\ldots + A_{2,n}B_{n,1} & A_{2,1}B_{1,2} + A_{2,2}B_{2,2} + \\ldots + A_{2,n}B_{n,2} & \\ldots & A_{2,1}B_{1,p} + A_{2,2}B_{2,p} + \\ldots + A_{2,n}B_{n,p} \\cr\n",
                "\\vdots & \\vdots & \\vdots & \\vdots \\cr\n",
                "A_{m,1}B_{1,1} + A_{m,2}B_{2,1} + \\ldots + A_{m,n}B_{n,1} & A_{m,1}B_{1,2} + A_{m,2}B_{2,2} + \\ldots + A_{m,n}B_{n,2} & \\ldots & A_{m,1}B_{1,p} + A_{m,2}B_{2,p} + \\ldots + A_{m,n}B_{n,p}\n",
                "\\end{bmatrix}\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "**Bij het dot product van 2 matrices $\\pmb{A}$ en $\\pmb{B}$, is resultaat altijd een matrix met evenveel rijen als er _rijen_ zijn in $\\pmb{A}$ en evenveel kolommen als er kolommen zijn in $\\pmb{B}$.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "58942b0b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Matrix B shape: (3, 4)\n",
                        "Dot product result:\n",
                        "[[ 74  80  86  92]\n",
                        " [173 188 203 218]]\n"
                    ]
                }
            ],
            "source": [
                "B = np.array([[7, 8, 9, 10], [11, 12, 13, 14], [15, 16, 17, 18]])\n",
                "print(f\"Matrix B shape: {B.shape}\")\n",
                "print(f\"Dot product result:\\n{np.dot(A, B)}\")  # Result is 2x4 matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "38155373",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[ 74,  80,  86,  92],\n",
                            "       [173, 188, 203, 218]])"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.array(\n",
                "    [\n",
                "        [\n",
                "            A[0, 0] * B[0, 0] + A[0, 1] * B[1, 0] + A[0, 2] * B[2, 0],\n",
                "            A[0, 0] * B[0, 1] + A[0, 1] * B[1, 1] + A[0, 2] * B[2, 1],\n",
                "            A[0, 0] * B[0, 2] + A[0, 1] * B[1, 2] + A[0, 2] * B[2, 2],\n",
                "            A[0, 0] * B[0, 3] + A[0, 1] * B[1, 3] + A[0, 2] * B[2, 3],\n",
                "        ],\n",
                "        [\n",
                "            A[1, 0] * B[0, 0] + A[1, 1] * B[1, 0] + A[1, 2] * B[2, 0],\n",
                "            A[1, 0] * B[0, 1] + A[1, 1] * B[1, 1] + A[1, 2] * B[2, 1],\n",
                "            A[1, 0] * B[0, 2] + A[1, 1] * B[1, 2] + A[1, 2] * B[2, 2],\n",
                "            A[1, 0] * B[0, 3] + A[1, 1] * B[1, 3] + A[1, 2] * B[2, 3],\n",
                "        ],\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "b41d96a9",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[ 74,  80,  86,  92],\n",
                            "       [173, 188, 203, 218]])"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# alternative notation for np.dot\n",
                "A @ B"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f9d04c43",
            "metadata": {},
            "source": [
                ":::{warning}\n",
                "$$\n",
                "\\pmb{A}\\pmb{B} \\neq \\pmb{B}\\pmb{A}\n",
                "$$\n",
                ":::"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "98213a26",
            "metadata": {},
            "source": [
                "### Toepassingen\n",
                "#### Lineaire gewichten\n",
                "Zowel bij lineaire regressie als bij simpele neurale netwerken zoals _{ref}`perceptrons <target-perceptron>`_ [](https://doi.org/10.1037%2Fh0042519), worden input features vertaald naar model outputs door gewogen sommen te nemen.\n",
                "Deze operatie komt neer op het dot product tussen de input vector $\\pmb{x}$ en een vector van gewichten $\\pmb{w}$: $\\pmb{w}^T\\pmb{x}$.\n",
                "\n",
                ":::{note} Perceptron\n",
                "Een perceptron is een vroeg model van een artificieel neuron, beschreven en gesimuleerd door [](https://doi.org/10.1037%2Fh0042519) die met dit werk verder bouwde op het werk van [](https://doi.org/10.1007%2FBF02478259). Inputs worden via een lineaire combinatie met gewichten en een _activatiefunctie_ vertaald naar een output.\n",
                "$$\n",
                "\\pmb{y} = f(\\pmb{x}) = h(\\pmb{w}^T\\pmb{x} + b)\n",
                "$$\n",
                "De model kon getraind worden om inputs _binair_ te classificeren (dus in te delen in 2 categorieën) op voorwaarde dat de categorieën overeen komen met een _lineair onderscheidbaar patroon_ in de inputs. De gewichten vector beschrijft een $n$-dimensionele _hyper plane_ om inputs binair op te delen. De term $b$ heet de _bias_ en geeft de translatie aan van de hyper plane aan ten opzichte van de oorsprong. \n",
                "In de originele vorm is de activatiefunctie $h$ een stapfunctie met output $1$ bij $\\pmb{w}^T\\pmb{x} + b > 0$ en $0$ bij $\\pmb{w}^T\\pmb{x} + b <= 0$ (de zogenaamde _Heaviside_ stapfunctie).\n",
                "```\n",
                "           x₁             x₂     ...     xₙ            1.0  \n",
                "           |              |              |              |\n",
                "           |              |              |              |\n",
                "           |              |              |              |\n",
                "           w₁             w₂     ...     wₙ             b\n",
                "            \\             |             /              /\n",
                "             \\            |            /              /\n",
                "              \\           |           /              /\n",
                "               \\          |          /              /\n",
                "                \\         |         /              /\n",
                "                 \\        |        /              /\n",
                "                  \\       |       /              /\n",
                "                   \\      |      /              /\n",
                "                    \\     |     /              /\n",
                "                     \\    |    /              /\n",
                "                      \\   |   /              /\n",
                "                       \\  |  /              /\n",
                "                        \\ | /              /\n",
                "                         \\|/              /\n",
                "                          v              v\n",
                "                        Dot product + bias\n",
                "                 z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b\n",
                "                                |\n",
                "                                v\n",
                "                        Activation function\n",
                "                              h(z)\n",
                "                                |\n",
                "                                v\n",
                "                             Output y\n",
                "```\n",
                ":::"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc273f12",
            "metadata": {},
            "source": [
                "#### Gewogen gemiddeldes\n",
                "Ieder _arithmetisch_ gemiddelde van een reeks datapunten van een bepaald type, kan uitgedrukt worden aan de hand van een dot product tussen een vector van _gewichten_ en de data-vector $\\pmb{y}.\\pmb{w}$,\n",
                "waarbij de som van de elementen van $\\pmb{w}$ exact $1$ is.  \n",
                "  \n",
                "Voor het algemene on-/gewogen gemiddelde krijgen we:\n",
                "$$\n",
                "\\begin{aligned}\n",
                "\\pmb{y}^T\\pmb{w} = \\sum_{i=1}^{n}y_iw_i = \\begin{bmatrix}\n",
                "y_1 & y_2 \\ldots & y_n\n",
                "\\end{bmatrix}\\begin{bmatrix}\n",
                "w_1 \\cr\n",
                "w_2 \\cr\n",
                "\\vdots  \\cr\n",
                "w_n\n",
                "\\end{bmatrix} &= y_1w_1 + y_2w_2 + \\ldots + y_nw_n \\\\\n",
                "w_1+w_2+\\ldots+w_n &= 1\n",
                "\\end{aligned}\n",
                "$$\n",
                "\n",
                "Voor een ongewogen gemiddelde krijgen we dan:\n",
                "$$\n",
                "\\pmb{y}^T\\pmb{w} = \\sum_{i=1}^{n}y_i\\frac{1}{n} = \\begin{bmatrix}\n",
                "y_1 & y_2 \\ldots & y_n\n",
                "\\end{bmatrix}\\begin{bmatrix}\n",
                "\\frac{1}{n} \\cr\n",
                "\\frac{1}{n} \\cr\n",
                "\\vdots  \\cr\n",
                "\\frac{1}{n}\n",
                "\\end{bmatrix} = \\frac{y_1}{n} + \\frac{y_2}{n} + \\ldots + \\frac{y_n}{n}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09e59ee1",
            "metadata": {},
            "source": [
                "#### Euclidische norm\n",
                "Vectoren hebben een grootte en een richting, zoals bijvoorbeeld de versnelling van een object in de ruimte $\\pmb{a} = [a_x a_y a_z]^T$.\n",
                "Vaak willen we de grootte uitdrukken in een scalaire waarde. Dat doen we aan de hand van een **norm-functie $L^p$** die gedefiniëerd is als:\n",
                "\n",
                "$$\n",
                "||\\pmb{x}||_p = \\begin{pmatrix}\\sum_{i}|x_i|^p\\end{pmatrix}^{\\frac{1}{p}}\n",
                "$$\n",
                "\n",
                "(target-norm)=\n",
                "**De norm van een vector in een bepaalde ruimte drukt de afstand uit tussen de oorsprong en het punt waar de vector betrekking op heeft**.\n",
                "(target-euclidean-norm)=\n",
                "In een **_Euclidische_ ruimte wordt die afstand gegeven door de $L^2$ norm. De $L^2$ norm van een vector bekomt men door het dot product te nemen van de vector met zichzelf**:  \n",
                "\n",
                "\\begin{align}\n",
                "||\\pmb{x}||_2 &= \\sqrt{\\sum_{i}x_i^2} \\\\\n",
                "&= \\sqrt{\\sum_{i}x_ix_i} \\\\\n",
                "&= \\sqrt{\\pmb{x}^T\\pmb{x}}\n",
                "\\end{align}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0b5cd3ba",
            "metadata": {},
            "source": [
                "(target-cosine-similarity)=\n",
                "#### _Cosine similarity_\n",
                "Vaak willen we ook de afstand _tussen_ 2 vectoren uitdrukken in een scalaire waarde, bijvoobeeld in de context van _similarity search_. In Euclidische ruimtes wordt dan vaak gekeken naar de cosinus van de hoek tussen 2 vectoren $cos({\\theta})$. Dit heet dan de _cosine similarity_ en wordt bekomen door het dot product te nemen en het te delen door de respectievelijke Euclidische normen:\n",
                "$$\n",
                "cos(\\theta) = \\frac{\\pmb{a}^T\\pmb{b}}{||\\pmb{a}||_2||\\pmb{b}||_2}\n",
                "$$\n",
                "Om dit te begrijpen hebben we de geometrische interpretatie van het dot-product nodig.  \n",
                "De _scalaire projectie_ van vector $\\pmb{a}$ op $\\pmb{b}$ in de Euclidische ruimte is gegeven als:\n",
                "\n",
                "$$\n",
                "a_b = ||\\pmb{a}||cos(\\theta)\n",
                "$$\n",
                "\n",
                "[![](../../../img/dot_product.jpg)](https://en.wikipedia.org/wiki/Dot_product)\n",
                "\n",
                "waarbij $\\theta$ de hoek is tussen beide vectoren. We kunnen deze geometrische definitie herschrijven als\n",
                "\n",
                "$$\n",
                "a_b = \\pmb{a}^T\\hat{\\pmb{b}}\n",
                "$$\n",
                "\n",
                "met $\\hat{\\pmb{b}}$ de unit vector (dwz. vector met lengte $1$) in de richting van $\\pmb{b}$:\n",
                "\n",
                "$$\n",
                "\\hat{\\pmb{b}} = \\frac{\\pmb{b}}{||\\pmb{b}||}\n",
                "$$\n",
                "\n",
                "Als we definities (10) en (11) aan elkaar gelijk stellen krijgen we:\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "\\pmb{a}^T\\frac{\\pmb{b}}{||\\pmb{b}||} &= ||\\pmb{a}||cos(\\theta) \\cr\n",
                "\\pmb{a}^T\\pmb{b} &= ||\\pmb{a}||||\\pmb{b}||cos(\\theta)\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "Het dot product van $\\pmb{a}$ en $\\pmb{b}$ is dus het product van (i) de grootte van de scalare projectie van $\\pmb{a}$ op $\\pmb{b}$ en (ii) de grootte van $\\pmb{b}$.\n",
                "De uitkomst zal groter worden naargelang:\n",
                "- $\\pmb{a}$ groter is\n",
                "- $\\pmb{b}$ groter is\n",
                "- $\\theta$ _kleiner_ is  \n",
                "  \n",
                "Als we terugkomen op de _cosine similarity_ kunnen we direct zien waar de formulering vandaan komt:\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "\\pmb{a}^T\\pmb{b} &= ||\\pmb{a}||||\\pmb{b}||cos(\\theta) \\cr\n",
                "cos(\\theta) &= \\frac{\\pmb{a}^T\\pmb{b}}{||\\pmb{a}||||\\pmb{b}||}\n",
                "\\end{align}\n",
                "$$"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ml-courses",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
